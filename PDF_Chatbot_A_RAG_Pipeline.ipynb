{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdefe49a"
      },
      "source": [
        "# **PDF Chatbot: A RAG Pipeline**\n",
        "\n",
        "This notebook demonstrates a simple Retrieval Augmented Generation (RAG) pipeline built within Google Colab, allowing you to interactively chat with your PDF documents. The goal is to process PDF files, create a searchable knowledge base from their content, and use a Large Language Model (LLM) to answer questions based on the retrieved information.\n",
        "\n",
        "The pipeline consists of the following main steps:\n",
        "\n",
        "1.  **PDF Processing:** Extracting text content from PDF files using `PyMuPDF`.\n",
        "2.  **Text Chunking:** Splitting the extracted text into smaller, manageable chunks.\n",
        "3.  **Embeddings:** Converting text chunks into numerical vector representations using a Sentence Transformer model.\n",
        "4.  **Vector Store:** Creating a FAISS index for efficient storage and retrieval of text embeddings.\n",
        "5.  **Retrieval:** Searching the vector store to find the most relevant text chunks for a given query.\n",
        "6.  **LLM Setup:** Loading and configuring a Large Language Model (LLM) for text generation (using `transformers`), including optional quantization for memory efficiency.\n",
        "7.  **Generation:** Using the LLM to generate an answer based on the user's query and the retrieved relevant text chunks.\n",
        "\n",
        "Key libraries used in this pipeline include:\n",
        "\n",
        "*   `PyMuPDF` (fitz) for PDF text extraction.\n",
        "*   `sentence-transformers` for creating text embeddings.\n",
        "*   `transformers` and `accelerate`/`bitsandbytes` for loading and managing the LLM.\n",
        "*   `faiss-cpu` for building the vector index and performing similarity search.\n",
        "*   `pandas` and `numpy` for data handling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7r7iv8ULxP5"
      },
      "source": [
        "## 1. Install Required Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZivwaSK9LxP6",
        "outputId": "28ad675c-246c-4e2e-ad75-5dfaf82247a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.1/60.1 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "%pip install -q transformers accelerate bitsandbytes\n",
        "%pip install -q sentence-transformers\n",
        "%pip install -q PyMuPDF tqdm pandas\n",
        "%pip install -q faiss-cpu\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNLhmKVZLxP7"
      },
      "source": [
        "## 2. Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ea_DYaiLxP7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import fitz  # PyMuPDF\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "import faiss\n",
        "from tqdm.auto import tqdm\n",
        "import re\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7bvQvO0LxP7"
      },
      "source": [
        "## 3. PDF Processing Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zahe70rDLxP8"
      },
      "outputs": [],
      "source": [
        "def text_formatter(text: str) -> str:\n",
        "    \"\"\"Clean and format text\"\"\"\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple whitespace with single space\n",
        "    text = re.sub(r'\\n+', '\\n', text)  # Replace multiple newlines with single newline\n",
        "    return text.strip()\n",
        "\n",
        "def open_and_read_pdf(pdf_path: str) -> list[dict]:\n",
        "    \"\"\"Extract text from PDF and return list of pages\"\"\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "    pages_text = []\n",
        "\n",
        "    for page_num in tqdm(range(len(doc)), desc=\"Reading PDF pages\"):\n",
        "        page = doc[page_num]\n",
        "        text = page.get_text()\n",
        "        text = text_formatter(text)\n",
        "\n",
        "        if text:  # Only add non-empty pages\n",
        "            pages_text.append({\n",
        "                'page_number': page_num + 1,\n",
        "                'text': text,\n",
        "                'char_count': len(text)\n",
        "            })\n",
        "\n",
        "    doc.close()\n",
        "    return pages_text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01Vf8UI3LxP8"
      },
      "source": [
        "## 4. Text Chunking\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBWcdBVPLxP9"
      },
      "outputs": [],
      "source": [
        "def split_text_into_chunks(text: str, chunk_size: int = 1000, overlap: int = 200) -> list[str]:\n",
        "    \"\"\"Split text into overlapping chunks\"\"\"\n",
        "    if len(text) <= chunk_size:\n",
        "        return [text]\n",
        "\n",
        "    chunks = []\n",
        "    start = 0\n",
        "\n",
        "    while start < len(text):\n",
        "        end = start + chunk_size\n",
        "\n",
        "        # Try to break at sentence boundary\n",
        "        if end < len(text):\n",
        "            # Look for sentence endings within the last 100 characters\n",
        "            search_start = max(start, end - 100)\n",
        "            sentence_end = text.rfind('.', search_start, end)\n",
        "            if sentence_end > start:\n",
        "                end = sentence_end + 1\n",
        "\n",
        "        chunk = text[start:end].strip()\n",
        "        if chunk:\n",
        "            chunks.append(chunk)\n",
        "\n",
        "        start = end - overlap\n",
        "        if start >= len(text):\n",
        "            break\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def create_chunks_from_pages(pages: list[dict], chunk_size: int = 1000, overlap: int = 200) -> list[dict]:\n",
        "    \"\"\"Create chunks from PDF pages\"\"\"\n",
        "    all_chunks = []\n",
        "\n",
        "    for page in tqdm(pages, desc=\"Creating chunks\"):\n",
        "        chunks = split_text_into_chunks(page['text'], chunk_size, overlap)\n",
        "\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            all_chunks.append({\n",
        "                'page_number': page['page_number'],\n",
        "                'chunk_id': f\"page_{page['page_number']}_chunk_{i+1}\",\n",
        "                'text': chunk,\n",
        "                'char_count': len(chunk)\n",
        "            })\n",
        "\n",
        "    return all_chunks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHVkUHYjLxP9"
      },
      "source": [
        "## 5. Embeddings and Vector Store\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPheofBOLxP9"
      },
      "outputs": [],
      "source": [
        "def create_embeddings(chunks: list[dict], model_name: str = \"all-MiniLM-L6-v2\") -> tuple:\n",
        "    \"\"\"Create embeddings for text chunks\"\"\"\n",
        "    print(f\"Loading embedding model: {model_name}\")\n",
        "    embedding_model = SentenceTransformer(model_name)\n",
        "\n",
        "    # Extract texts\n",
        "    texts = [chunk['text'] for chunk in chunks]\n",
        "\n",
        "    print(\"Creating embeddings...\")\n",
        "    embeddings = embedding_model.encode(texts, show_progress_bar=True)\n",
        "\n",
        "    return embeddings, embedding_model\n",
        "\n",
        "def create_faiss_index(embeddings: np.ndarray) -> faiss.Index:\n",
        "    \"\"\"Create FAISS index for similarity search\"\"\"\n",
        "    dimension = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatIP(dimension)  # Inner product (cosine similarity)\n",
        "\n",
        "    # Normalize embeddings for cosine similarity\n",
        "    faiss.normalize_L2(embeddings)\n",
        "    index.add(embeddings.astype('float32'))\n",
        "\n",
        "    return index\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wT1srDVjLxP-"
      },
      "source": [
        "## 6. Retrieval Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eYJjsPZLxP-"
      },
      "outputs": [],
      "source": [
        "def retrieve_relevant_chunks(query: str,\n",
        "                           embedding_model: SentenceTransformer,\n",
        "                           index: faiss.Index,\n",
        "                           chunks: list[dict],\n",
        "                           top_k: int = 5) -> list[dict]:\n",
        "    \"\"\"Retrieve most relevant chunks for a query\"\"\"\n",
        "    # Create query embedding\n",
        "    query_embedding = embedding_model.encode([query])\n",
        "    faiss.normalize_L2(query_embedding)\n",
        "\n",
        "    # Search for similar chunks\n",
        "    scores, indices = index.search(query_embedding.astype('float32'), top_k)\n",
        "\n",
        "    # Get relevant chunks with scores\n",
        "    relevant_chunks = []\n",
        "    for i, (score, idx) in enumerate(zip(scores[0], indices[0])):\n",
        "        chunk = chunks[idx].copy()\n",
        "        chunk['similarity_score'] = float(score)\n",
        "        chunk['rank'] = i + 1\n",
        "        relevant_chunks.append(chunk)\n",
        "\n",
        "    return relevant_chunks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZuA1u3mLxP-"
      },
      "source": [
        "## 7. LLM Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10EXrnarLxP_"
      },
      "outputs": [],
      "source": [
        "def setup_llm(model_name: str = \"microsoft/DialoGPT-medium\", use_quantization: bool = True):\n",
        "    \"\"\"Setup LLM for text generation\"\"\"\n",
        "    print(f\"Loading LLM: {model_name}\")\n",
        "\n",
        "    # Setup quantization for memory efficiency\n",
        "    if use_quantization and torch.cuda.is_available():\n",
        "        quantization_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_compute_dtype=torch.float16,\n",
        "            bnb_4bit_use_double_quant=True,\n",
        "            bnb_4bit_quant_type=\"nf4\"\n",
        "        )\n",
        "    else:\n",
        "        quantization_config = None\n",
        "\n",
        "    # Load tokenizer and model\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        quantization_config=quantization_config,\n",
        "        device_map=\"auto\",\n",
        "        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "    )\n",
        "\n",
        "    # Add padding token if not present\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    return model, tokenizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX5fidGOLxP_"
      },
      "source": [
        "## 8. RAG Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeAW9l3PLxP_"
      },
      "outputs": [],
      "source": [
        "def generate_answer(query: str,\n",
        "                   relevant_chunks: list[dict],\n",
        "                   model,\n",
        "                   tokenizer,\n",
        "                   max_length: int = 512) -> str:\n",
        "    \"\"\"Generate answer using retrieved context\"\"\"\n",
        "    # Create context from relevant chunks\n",
        "    context = \"\\n\\n\".join([chunk['text'] for chunk in relevant_chunks])\n",
        "\n",
        "    # Create prompt\n",
        "    prompt = f\"\"\"Context: {context}\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "Answer: Based on the provided context, \"\"\"\n",
        "\n",
        "    # Tokenize input\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=max_length)\n",
        "\n",
        "    # Move to same device as model\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = {k: v.cuda() for k, v in inputs.items()}\n",
        "\n",
        "    # Generate response\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=200,\n",
        "            temperature=0.7,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    # Decode response\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Extract only the answer part\n",
        "    answer = response.split(\"Answer: Based on the provided context, \")[-1]\n",
        "\n",
        "    return answer.strip()\n",
        "\n",
        "def rag_pipeline(query: str,\n",
        "                embedding_model: SentenceTransformer,\n",
        "                index: faiss.Index,\n",
        "                chunks: list[dict],\n",
        "                model,\n",
        "                tokenizer,\n",
        "                top_k: int = 5) -> dict:\n",
        "    \"\"\"Complete RAG pipeline\"\"\"\n",
        "    # Retrieve relevant chunks\n",
        "    relevant_chunks = retrieve_relevant_chunks(query, embedding_model, index, chunks, top_k)\n",
        "\n",
        "    # Generate answer\n",
        "    answer = generate_answer(query, relevant_chunks, model, tokenizer)\n",
        "\n",
        "    return {\n",
        "        'query': query,\n",
        "        'answer': answer,\n",
        "        'relevant_chunks': relevant_chunks,\n",
        "        'sources': [f\"Page {chunk['page_number']}\" for chunk in relevant_chunks]\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "df407247",
        "outputId": "571f4fdc-0779-4b0c-93d8-19c2a3b778c2"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  # Assuming only one file is uploaded, set the PDF_PATH\n",
        "  PDF_PATH = \"/content/\" + fn\n",
        "  print(f\"\\nPDF_PATH set to: {PDF_PATH}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1c9b0c4d-385d-48c3-937d-cffbc6754c08\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1c9b0c4d-385d-48c3-937d-cffbc6754c08\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sample_pdf.pdf to sample_pdf.pdf\n",
            "User uploaded file \"sample_pdf.pdf\" with length 169506 bytes\n",
            "\n",
            "PDF_PATH set to: /content/sample_pdf.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y4sL_pDLxQA"
      },
      "source": [
        "## 9. Complete RAG Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460,
          "referenced_widgets": [
            "df68ae97ee144e2d9aa07f7f7839139c",
            "dc6a2ae904234fd59f8f73b2aae69a73",
            "964fb2135cd34950b584789a7250a5ea",
            "b51150609a6f4976abb17403793921ee",
            "4c19fda3e9224d3cb1703ed84eac18ad",
            "e50f2d0bd6874ce69932d541dd69c6b3",
            "86ef115ef9f64840bd9bf8901cbc9be1",
            "c84ae41d72ff40e29ff7ad3e2accd85d",
            "2b7ab01d4eea4a47a55d8b6b208f9f0c",
            "73ed510cff9344c699429ed9a1f17702",
            "d82437aab2424f29b95989668692a4e1",
            "f8c58e6c54134f93b10baca866f8e521",
            "3dcb43ffd6594694a15c054b9d403915",
            "ab49c52842924a0a8e428ced816f5080",
            "b17f3cc4b442476cb58720c5d45cd811",
            "fae79f4cfbb24faab5a90836ec38e4b1",
            "0216247bdd8346bd94833432a84e10fa",
            "5395b7c376554332a1d88899bcaad340",
            "bfac780f42784fe9ad690b249f91e828",
            "64f07b110d9c4ec89785e8eb85732503",
            "2dde63bfdf4045b8b4cc403b61d95e74",
            "6bb19135a17d48f59c84533e05f140b0",
            "41fae2e5536e4653b5a0470c9daa9b3f",
            "206addbfd37344d784e0e35744b55e7c",
            "4465e7d7613345a38e68fe5c560bfc3f",
            "dca64e26a7284163a9e86dc10a68ef6d",
            "f24fde22f775418ab456c518bb0a6047",
            "39e1c1e2be6d4814a73602d6daf4aa50",
            "56ce369975884c359e7de80bab578dbc",
            "69dead12d8de471d9b78b28f8fac5586",
            "62db18b71c1246e9a12fbe0d6657e49a",
            "a2e2730e57a84ad888e4fbbb8867de7e",
            "1ed3f6ea3c9440ad93eaff84de253fea"
          ]
        },
        "id": "260c59c6",
        "outputId": "1bb9aecc-c367-4d92-ae01-9995d3fb486a"
      },
      "source": [
        "# This cell will now use the PDF_PATH variable set by the upload cell\n",
        "\n",
        "# Step 1: Process PDF\n",
        "print(\"Step 1: Processing PDF...\")\n",
        "if 'PDF_PATH' not in globals():\n",
        "    print(\"Please upload a PDF file first using the cell above.\")\n",
        "else:\n",
        "    pages = open_and_read_pdf(PDF_PATH)\n",
        "    print(f\"Extracted {len(pages)} pages\")\n",
        "\n",
        "    # Step 2: Create chunks\n",
        "    print(\"\\nStep 2: Creating text chunks...\")\n",
        "    chunks = create_chunks_from_pages(pages, chunk_size=1000, overlap=200)\n",
        "    print(f\"Created {len(chunks)} chunks\")\n",
        "\n",
        "    # Step 3: Create embeddings\n",
        "    print(\"\\nStep 3: Creating embeddings...\")\n",
        "    embeddings, embedding_model = create_embeddings(chunks)\n",
        "    print(f\"Created embeddings with shape: {embeddings.shape}\")\n",
        "\n",
        "    # Step 4: Create FAISS index\n",
        "    print(\"\\nStep 4: Creating FAISS index...\")\n",
        "    index = create_faiss_index(embeddings)\n",
        "    print(f\"FAISS index created with {index.ntotal} vectors\")\n",
        "\n",
        "    # Step 5: Setup LLM\n",
        "    print(\"\\nStep 5: Setting up LLM...\")\n",
        "    # Use the TinyLlama model ID\n",
        "    model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "    model, tokenizer = setup_llm(model_name, use_quantization=True)\n",
        "    print(\"LLM setup complete!\")\n",
        "\n",
        "    print(\"\\nâœ… RAG pipeline is ready!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Processing PDF...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Reading PDF pages:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df68ae97ee144e2d9aa07f7f7839139c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted 2 pages\n",
            "\n",
            "Step 2: Creating text chunks...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating chunks:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8c58e6c54134f93b10baca866f8e521"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 8 chunks\n",
            "\n",
            "Step 3: Creating embeddings...\n",
            "Loading embedding model: all-MiniLM-L6-v2\n",
            "Creating embeddings...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41fae2e5536e4653b5a0470c9daa9b3f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created embeddings with shape: (8, 384)\n",
            "\n",
            "Step 4: Creating FAISS index...\n",
            "FAISS index created with 8 vectors\n",
            "\n",
            "Step 5: Setting up LLM...\n",
            "Loading LLM: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu and disk.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM setup complete!\n",
            "\n",
            "âœ… RAG pipeline is ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiwBsh5aLxQA"
      },
      "source": [
        "## 10. Ask Questions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wj79abaTLxQB",
        "outputId": "bdd957b9-39df-43a5-92ba-566075880f75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "â“ Question: What are the main topics discussed in this document?\n",
            "\n",
            "ðŸ’¡ Answer: Context: All You Need\" paper) still dominates, new variants and improvements are constantly emerging to make them more efficient and capable of handling longer contexts (e.g., processing entire books at once). â€¢ Diffusion Models: This is the architecture that powers most of the current state-of-the-art image generators (like Stable Diffusion and Midjourney). It works by progressively adding noise to data and then learning to reverse the process, creating highly detailed and coherent images from chaos. â€¢ Multimodal Architectures: Research is focused on the best ways to fuse different data types (text, vision, audio) into a single, cohesive model that has a deep, unified understanding of the world. 5. Practical Applications and Democratization The \"how\" of using AI is becoming as important as the \"what.\" â€¢ Retrieval-Augmented Generation (RAG): This is a pivotal technique for making LLMs useful for businesses.\n",
            "\n",
            "I (XAI): There's a massive push to make the \"black box\" of complex models more transparent. Why did the model make that decision? This is critical for high-stakes fields like healthcare, finance, and criminal justice. â€¢ Bias, Fairness, and Safety: Actively developing techniques to identify and mitigate biases in training data and model outputs. This includes \"red teaming\" models to find harmful behaviors before release and implementing robust guardrails. â€¢ AI Regulation: Governments worldwide are scrambling to create rules. The EU's AI Act is leading the charge, creating a risk-based regulatory framework. Companies are now building internal governance teams to ensure compliance. 3. The Hardware and Infrastructure Revolution You can't run a trillion-parameter model on a standard laptop. The demand for more powerful and efficient computing is fueling its own trends.\n",
            "\n",
            "â€¢ The NPU (Neural Processing Unit): Chip manufacturers (like Intel, AMD, Apple, and Qualcomm) are integrating dedicated AI accelerators (NPUs) directly into CPUs and consumer devices. This is what powers the \"AI PC\" trend, allowing you to run models locally on your laptop or phone for better privacy and speed. â€¢ Custom AI Chips: Innovators like NVIDIA and Arm are developing proprietary AI chips for high-end gaming, AI-powered robots, and autonomous vehicles. These chips are designed to work with the latest AI models and provide the processing power needed to run them efficiently. â€¢ Artificial Intelligence as a Service (AIaaS): This model is the future of AI. Platforms like AWS and Microsoft Azure offer a wide range of AI services and tools for businesses, making it easier to get started. â€¢ Cloud Gaming: This is the next big trend in gaming. Cloud gaming services like Google Stadia and Microsoft xCloud offer AI-powered gaming for mobile devices. 4. The \"What\" of AI: What are the most promising applications of AI for businesses? â€¢ Customer Engagement: AI is transforming customer service by allowing businesses to provide personalized, A\n",
            "\n",
            "ðŸ“š Sources: Page 2, Page 1, Page 2, Page 1, Page 1\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "def ask_question(question: str):\n",
        "    \"\"\"Ask a question and get an answer with sources\"\"\"\n",
        "    result = rag_pipeline(question, embedding_model, index, chunks, model, tokenizer)\n",
        "\n",
        "    print(f\"\\nâ“ Question: {result['query']}\")\n",
        "    print(f\"\\nðŸ’¡ Answer: {result['answer']}\")\n",
        "    print(f\"\\nðŸ“š Sources: {', '.join(result['sources'])}\")\n",
        "\n",
        "    return result\n",
        "\n",
        "# Ask your questions here\n",
        "question = \"What are the main topics discussed in this document?\"\n",
        "result = ask_question(question)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_BNRT3GLxQB"
      },
      "source": [
        "## 11. Interactive Chat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17zTwPPHLxQB",
        "outputId": "4c3f5a06-e6eb-40c0-e364-3c9185b5a943"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ¤– RAG Chatbot Ready! Type 'quit' to exit.\n",
            "\n",
            "You: what is XAI?\n",
            "\n",
            "ðŸ¤– Bot: Context: efficient \"fine-tuned\" models that excel at a particular job (e.g., legal document review, medical diagnosis assistance) at a fraction of the cost. This is often called \"Small Language Models (SLMs)\". â€¢ AI Agents: The next step is moving from a conversational chatbot to an autonomous agent. These are AI systems that can be given a high-level goal (e.g., \"Plan a 5-day vacation to Tokyo\"), and then independently break it down into steps: researching flights, booking hotels, creating an itinerary, and making restaurant reservations by using tools and APIs. 2. The Rise of \"Responsible AI\" and Governance As AI becomes more powerful, the backlash and concern about its ethical implications have grown exponentially. This is no longer an afterthought but a core business requirement. â€¢ Explainable AI (XAI): There's a massive push to make the \"black box\" of complex models more transparent. Why did the model make that decision? This is critical for high-stakes fields like healthcare, finance, and\n",
            "\n",
            "I (XAI): There's a massive push to make the \"black box\" of complex models more transparent. Why did the model make that decision? This is critical for high-stakes fields like healthcare, finance, and criminal justice. â€¢ Bias, Fairness, and Safety: Actively developing techniques to identify and mitigate biases in training data and model outputs. This includes \"red teaming\" models to find harmful behaviors before release and implementing robust guardrails. â€¢ AI Regulation: Governments worldwide are scrambling to create rules. The EU's AI Act is leading the charge, creating a risk-based regulatory framework. Companies are now building internal governance teams to ensure compliance. 3. The Hardware and Infrastructure Revolution You can't run a trillion-parameter model on a standard laptop. The demand for more powerful and efficient computing is fueling its own trends.\n",
            "\n",
            "â€¢ The NPU (Neural Processing Unit): Chip manufacturers (like Intel, AMD, Apple, and Qualcomm) are integrating dedicated AI accelerators (NPUs) directly into CPUs and consumer devices. This allows for parallel processing of data, reducing inference time. â€¢ The Cloud: As companies scale up, cloud providers like AWS, Azure, and Google Cloud offer a range of services, from high-performance computing (HPC) to low-cost AI-powered services. â€¢ Edge Computing: As more data is produced by IoT devices and sensors, edge computing is becoming increasingly popular. Edge computing is the process of processing data at the point of origin, avoiding the need to send data back to a central server. 4. The Impact on Education and Training: AI is transforming education and training. â€¢ AI-Powered Learning: AI is being used to create more personalized and interactive learning experiences. This includes conversational chatbots that provide real-time feedback and reinforcement, as well as gamification and immersive learning experiences. â€¢ AI-Powered Assessment: In line with the\n",
            "ðŸ“š Sources: Page 1, Page 1, Page 2, Page 2, Page 2\n",
            "\n",
            "You: quit\n",
            "Goodbye! ðŸ‘‹\n"
          ]
        }
      ],
      "source": [
        "# Interactive chat loop\n",
        "def interactive_chat():\n",
        "    print(\"\\nðŸ¤– RAG Chatbot Ready! Type 'quit' to exit.\\n\")\n",
        "\n",
        "    while True:\n",
        "        question = input(\"You: \")\n",
        "\n",
        "        if question.lower() in ['quit', 'exit', 'bye']:\n",
        "            print(\"Goodbye! ðŸ‘‹\")\n",
        "            break\n",
        "\n",
        "        if question.strip():\n",
        "            try:\n",
        "                result = rag_pipeline(question, embedding_model, index, chunks, model, tokenizer)\n",
        "                print(f\"\\nðŸ¤– Bot: {result['answer']}\")\n",
        "                print(f\"ðŸ“š Sources: {', '.join(result['sources'])}\\n\")\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ Error: {str(e)}\\n\")\n",
        "\n",
        "# Uncomment the line below to start interactive chat\n",
        "interactive_chat()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8vQR95ULxQB"
      },
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "df68ae97ee144e2d9aa07f7f7839139c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc6a2ae904234fd59f8f73b2aae69a73",
              "IPY_MODEL_964fb2135cd34950b584789a7250a5ea",
              "IPY_MODEL_b51150609a6f4976abb17403793921ee"
            ],
            "layout": "IPY_MODEL_4c19fda3e9224d3cb1703ed84eac18ad"
          }
        },
        "dc6a2ae904234fd59f8f73b2aae69a73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e50f2d0bd6874ce69932d541dd69c6b3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_86ef115ef9f64840bd9bf8901cbc9be1",
            "value": "Readingâ€‡PDFâ€‡pages:â€‡100%"
          }
        },
        "964fb2135cd34950b584789a7250a5ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c84ae41d72ff40e29ff7ad3e2accd85d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b7ab01d4eea4a47a55d8b6b208f9f0c",
            "value": 2
          }
        },
        "b51150609a6f4976abb17403793921ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73ed510cff9344c699429ed9a1f17702",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d82437aab2424f29b95989668692a4e1",
            "value": "â€‡2/2â€‡[00:00&lt;00:00,â€‡29.83it/s]"
          }
        },
        "4c19fda3e9224d3cb1703ed84eac18ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e50f2d0bd6874ce69932d541dd69c6b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86ef115ef9f64840bd9bf8901cbc9be1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c84ae41d72ff40e29ff7ad3e2accd85d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b7ab01d4eea4a47a55d8b6b208f9f0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "73ed510cff9344c699429ed9a1f17702": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d82437aab2424f29b95989668692a4e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8c58e6c54134f93b10baca866f8e521": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3dcb43ffd6594694a15c054b9d403915",
              "IPY_MODEL_ab49c52842924a0a8e428ced816f5080",
              "IPY_MODEL_b17f3cc4b442476cb58720c5d45cd811"
            ],
            "layout": "IPY_MODEL_fae79f4cfbb24faab5a90836ec38e4b1"
          }
        },
        "3dcb43ffd6594694a15c054b9d403915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0216247bdd8346bd94833432a84e10fa",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5395b7c376554332a1d88899bcaad340",
            "value": "Creatingâ€‡chunks:â€‡100%"
          }
        },
        "ab49c52842924a0a8e428ced816f5080": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfac780f42784fe9ad690b249f91e828",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_64f07b110d9c4ec89785e8eb85732503",
            "value": 2
          }
        },
        "b17f3cc4b442476cb58720c5d45cd811": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dde63bfdf4045b8b4cc403b61d95e74",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6bb19135a17d48f59c84533e05f140b0",
            "value": "â€‡2/2â€‡[00:00&lt;00:00,â€‡126.72it/s]"
          }
        },
        "fae79f4cfbb24faab5a90836ec38e4b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0216247bdd8346bd94833432a84e10fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5395b7c376554332a1d88899bcaad340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfac780f42784fe9ad690b249f91e828": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64f07b110d9c4ec89785e8eb85732503": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2dde63bfdf4045b8b4cc403b61d95e74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bb19135a17d48f59c84533e05f140b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41fae2e5536e4653b5a0470c9daa9b3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_206addbfd37344d784e0e35744b55e7c",
              "IPY_MODEL_4465e7d7613345a38e68fe5c560bfc3f",
              "IPY_MODEL_dca64e26a7284163a9e86dc10a68ef6d"
            ],
            "layout": "IPY_MODEL_f24fde22f775418ab456c518bb0a6047"
          }
        },
        "206addbfd37344d784e0e35744b55e7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39e1c1e2be6d4814a73602d6daf4aa50",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_56ce369975884c359e7de80bab578dbc",
            "value": "Batches:â€‡100%"
          }
        },
        "4465e7d7613345a38e68fe5c560bfc3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69dead12d8de471d9b78b28f8fac5586",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62db18b71c1246e9a12fbe0d6657e49a",
            "value": 1
          }
        },
        "dca64e26a7284163a9e86dc10a68ef6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2e2730e57a84ad888e4fbbb8867de7e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1ed3f6ea3c9440ad93eaff84de253fea",
            "value": "â€‡1/1â€‡[00:01&lt;00:00,â€‡â€‡1.48s/it]"
          }
        },
        "f24fde22f775418ab456c518bb0a6047": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39e1c1e2be6d4814a73602d6daf4aa50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56ce369975884c359e7de80bab578dbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69dead12d8de471d9b78b28f8fac5586": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62db18b71c1246e9a12fbe0d6657e49a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2e2730e57a84ad888e4fbbb8867de7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ed3f6ea3c9440ad93eaff84de253fea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}